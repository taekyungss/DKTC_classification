{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c024263-365c-4a39-aafe-ecb8b76d67ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ [KoELECTRA] ì‚¬ìš© ì¥ì¹˜: cuda\n",
      "âœ… ìœ„í˜‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 3950ê°œ\n",
      "ğŸ“‚ ì‚¬ìš©í•  ì¼ë°˜ ëŒ€í™” íŒŒì¼: normal_conversation.csv\n",
      "âœ… ì¼ë°˜ ëŒ€í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 800ê°œ\n",
      "ğŸ“Š ìµœì¢… í•™ìŠµ ë°ì´í„° ê°œìˆ˜: 4750ê°œ\n",
      "ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: monologg/koelectra-base-v3-discriminator\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d857ffe0615b49b49548f1b5c28e005c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/197 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mElectraForSequenceClassification LOAD REPORT\u001b[0m from: monologg/koelectra-base-v3-discriminator\n",
      "Key                                               | Status     | \n",
      "--------------------------------------------------+------------+-\n",
      "discriminator_predictions.dense_prediction.weight | UNEXPECTED | \n",
      "discriminator_predictions.dense.bias              | UNEXPECTED | \n",
      "electra.embeddings.position_ids                   | UNEXPECTED | \n",
      "discriminator_predictions.dense.weight            | UNEXPECTED | \n",
      "discriminator_predictions.dense_prediction.bias   | UNEXPECTED | \n",
      "classifier.dense.bias                             | MISSING    | \n",
      "classifier.out_proj.weight                        | MISSING    | \n",
      "classifier.dense.weight                           | MISSING    | \n",
      "classifier.out_proj.bias                          | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1885c9898dbd4eaa841f283d00b91ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53494ab7b1824860a98f92c53c879ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/950 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“˜ KoELECTRA í•™ìŠµ ì‹œì‘! (ì•½ 5~10ë¶„ ì†Œìš”)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1190' max='1190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1190/1190 13:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.409734</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.894658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.316965</td>\n",
       "      <td>0.910526</td>\n",
       "      <td>0.910063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.610365</td>\n",
       "      <td>0.332341</td>\n",
       "      <td>0.917895</td>\n",
       "      <td>0.917866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.610365</td>\n",
       "      <td>0.370095</td>\n",
       "      <td>0.913684</td>\n",
       "      <td>0.913761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.146016</td>\n",
       "      <td>0.368766</td>\n",
       "      <td>0.915789</td>\n",
       "      <td>0.915815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2753252f3d4b9589b8a07f51e340dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2db09366bb8d466fa3abfa62b831f85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9544869d2a6a432e81865799c1c311e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fae65968d0d4c4b8f8ea32cf118ed1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad4af9f5e2c4ff68302a16edaec04fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['electra.embeddings.LayerNorm.weight', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.output.LayerNorm.bias'].\n",
      "There were unexpected keys in the checkpoint model loaded: ['electra.embeddings.LayerNorm.beta', 'electra.embeddings.LayerNorm.gamma', 'electra.encoder.layer.0.attention.output.LayerNorm.beta', 'electra.encoder.layer.0.attention.output.LayerNorm.gamma', 'electra.encoder.layer.0.output.LayerNorm.beta', 'electra.encoder.layer.0.output.LayerNorm.gamma', 'electra.encoder.layer.1.attention.output.LayerNorm.beta', 'electra.encoder.layer.1.attention.output.LayerNorm.gamma', 'electra.encoder.layer.1.output.LayerNorm.beta', 'electra.encoder.layer.1.output.LayerNorm.gamma', 'electra.encoder.layer.2.attention.output.LayerNorm.beta', 'electra.encoder.layer.2.attention.output.LayerNorm.gamma', 'electra.encoder.layer.2.output.LayerNorm.beta', 'electra.encoder.layer.2.output.LayerNorm.gamma', 'electra.encoder.layer.3.attention.output.LayerNorm.beta', 'electra.encoder.layer.3.attention.output.LayerNorm.gamma', 'electra.encoder.layer.3.output.LayerNorm.beta', 'electra.encoder.layer.3.output.LayerNorm.gamma', 'electra.encoder.layer.4.attention.output.LayerNorm.beta', 'electra.encoder.layer.4.attention.output.LayerNorm.gamma', 'electra.encoder.layer.4.output.LayerNorm.beta', 'electra.encoder.layer.4.output.LayerNorm.gamma', 'electra.encoder.layer.5.attention.output.LayerNorm.beta', 'electra.encoder.layer.5.attention.output.LayerNorm.gamma', 'electra.encoder.layer.5.output.LayerNorm.beta', 'electra.encoder.layer.5.output.LayerNorm.gamma', 'electra.encoder.layer.6.attention.output.LayerNorm.beta', 'electra.encoder.layer.6.attention.output.LayerNorm.gamma', 'electra.encoder.layer.6.output.LayerNorm.beta', 'electra.encoder.layer.6.output.LayerNorm.gamma', 'electra.encoder.layer.7.attention.output.LayerNorm.beta', 'electra.encoder.layer.7.attention.output.LayerNorm.gamma', 'electra.encoder.layer.7.output.LayerNorm.beta', 'electra.encoder.layer.7.output.LayerNorm.gamma', 'electra.encoder.layer.8.attention.output.LayerNorm.beta', 'electra.encoder.layer.8.attention.output.LayerNorm.gamma', 'electra.encoder.layer.8.output.LayerNorm.beta', 'electra.encoder.layer.8.output.LayerNorm.gamma', 'electra.encoder.layer.9.attention.output.LayerNorm.beta', 'electra.encoder.layer.9.attention.output.LayerNorm.gamma', 'electra.encoder.layer.9.output.LayerNorm.beta', 'electra.encoder.layer.9.output.LayerNorm.gamma', 'electra.encoder.layer.10.attention.output.LayerNorm.beta', 'electra.encoder.layer.10.attention.output.LayerNorm.gamma', 'electra.encoder.layer.10.output.LayerNorm.beta', 'electra.encoder.layer.10.output.LayerNorm.gamma', 'electra.encoder.layer.11.attention.output.LayerNorm.beta', 'electra.encoder.layer.11.attention.output.LayerNorm.gamma', 'electra.encoder.layer.11.output.LayerNorm.beta', 'electra.encoder.layer.11.output.LayerNorm.gamma'].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "867536541a24415b90e37d5b4db72e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Writing model shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ './final_model_ko' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# ==========================================\n",
    "# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í™˜ê²½ ì„¤ì •\n",
    "# ==========================================\n",
    "try:\n",
    "    from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "    from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "    from datasets import Dataset\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except ImportError:\n",
    "    sys.exit(\"âŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. !pip install transformers datasets accelerate scikit-learn ì‹¤í–‰ í•„ìš”\")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸš€ [KoELECTRA] ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©\n",
    "# ==========================================\n",
    "url = \"https://raw.githubusercontent.com/tunib-ai/DKTC/main/data/train.csv\"\n",
    "try:\n",
    "    df_threat = pd.read_csv(url)[['class', 'conversation']]\n",
    "    print(f\"âœ… ìœ„í˜‘ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_threat)}ê°œ\")\n",
    "except Exception as e:\n",
    "    sys.exit(f\"âŒ ìœ„í˜‘ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "# ì¼ë°˜ ëŒ€í™” íŒŒì¼ ë¡œë“œ (ìš°ì„ ìˆœìœ„: ì—…ë¡œë“œëœ íŒŒì¼ëª…)\n",
    "normal_file = \"normal_conversation (1).csv\"\n",
    "if not os.path.exists(normal_file):\n",
    "    # ëŒ€ì²´ íŒŒì¼ëª… í™•ì¸ (ê´„í˜¸ ì—†ëŠ” ë²„ì „)\n",
    "    if os.path.exists(\"normal_conversation.csv\"):\n",
    "        normal_file = \"normal_conversation.csv\"\n",
    "    else:\n",
    "        sys.exit(f\"âŒ '{normal_file}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"ğŸ“‚ ì‚¬ìš©í•  ì¼ë°˜ ëŒ€í™” íŒŒì¼: {normal_file}\")\n",
    "df_normal = pd.read_csv(normal_file)\n",
    "df_normal['conversation'] = df_normal['conversation'].str.replace(r'(^|\\n)[AB]:\\s*', '', regex=True)\n",
    "\n",
    "# ì»¬ëŸ¼ëª… í†µì¼\n",
    "if 'class' not in df_normal.columns:\n",
    "    df_normal['class'] = 'ì¼ë°˜ ëŒ€í™”'\n",
    "df_normal = df_normal[['class', 'conversation']]\n",
    "print(f\"âœ… ì¼ë°˜ ëŒ€í™” ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df_normal)}ê°œ\")\n",
    "\n",
    "# ë³‘í•© ë° ì…”í”Œ\n",
    "df_final = pd.concat([df_threat, df_normal], ignore_index=True)\n",
    "df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(f\"ğŸ“Š ìµœì¢… í•™ìŠµ ë°ì´í„° ê°œìˆ˜: {len(df_final)}ê°œ\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. ë¼ë²¨ ì¸ì½”ë”© & ë°ì´í„°ì…‹ ë³€í™˜\n",
    "# ==========================================\n",
    "label_map = {\n",
    "    'í˜‘ë°• ëŒ€í™”': 0, 'ê°ˆì·¨ ëŒ€í™”': 1, 'ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”': 2, 'ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”': 3,\n",
    "    'í˜‘ë°•': 0, 'ê°ˆì·¨': 1, 'ì§ì¥ ë‚´ ê´´ë¡­í˜': 2, 'ê¸°íƒ€ ê´´ë¡­í˜': 3,\n",
    "    'ì¼ë°˜ ëŒ€í™”': 4\n",
    "}\n",
    "df_final['label'] = df_final['class'].map(label_map)\n",
    "df_final = df_final.dropna(subset=['label'])\n",
    "df_final['label'] = df_final['label'].astype(int)\n",
    "\n",
    "train_df, val_df = train_test_split(df_final, test_size=0.2, random_state=42, stratify=df_final['label'])\n",
    "train_dataset = Dataset.from_pandas(train_df[['conversation', 'label']])\n",
    "val_dataset = Dataset.from_pandas(val_df[['conversation', 'label']])\n",
    "\n",
    "# ==========================================\n",
    "# 4. ëª¨ë¸ & í† í¬ë‚˜ì´ì € (KoELECTRA)\n",
    "# ==========================================\n",
    "# ğŸš¨ [ë³€ê²½ë¨] KoELECTRA ëª¨ë¸ ì‚¬ìš© (-discriminator í•„ìˆ˜!)\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "print(f\"ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘: {MODEL_NAME}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5).to(device)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"conversation\"], truncation=True, max_length=256)\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# ==========================================\n",
    "# 5. í•™ìŠµ (Training)\n",
    "# ==========================================\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average='weighted')\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_ko\",     # [ë³€ê²½ë¨] ê²°ê³¼ í´ë”ëª…\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",  \n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    data_collator=data_collator,   \n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“˜ KoELECTRA í•™ìŠµ ì‹œì‘! (ì•½ 5~10ë¶„ ì†Œìš”)\")\n",
    "trainer.train()\n",
    "\n",
    "# ==========================================\n",
    "# 6. ëª¨ë¸ ì €ì¥\n",
    "# ==========================================\n",
    "SAVE_PATH = \"./final_model_ko\" # [ë³€ê²½ë¨] ì €ì¥ í´ë”ëª…\n",
    "model.save_pretrained(SAVE_PATH)\n",
    "tokenizer.save_pretrained(SAVE_PATH)\n",
    "print(f\"\\nâœ… í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ '{SAVE_PATH}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4109279-e0e7-428b-a7f8-6db3fd3bb597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‚¬ìš© ì¥ì¹˜: cuda\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 500ê°œ\n",
      "ë°ì´í„° ì˜ˆì‹œ: ID=t_000, ë‚´ìš©={'text': 'ì•„ê°€ì”¨ ë‹´ë°°í•œê°‘ì£¼ì†Œ ë„¤ 4500ì›ì…ë‹ˆë‹¤ ì–´ ë„¤ ì§€ê°‘ì–´ë””ê°”ì§€ ì—ì´ ë²„ìŠ¤ì—ì„œ ìƒì–´ë²„ë ¸ë‚˜ë³´ë„¤ ê·¸ëŸ¼ ì·¨ì†Œí• ê¹Œìš” ì•„ê°€ì”¨ ë‚´ ì—¬ê¸°ë‹¨ê³¨ì´ë‹ˆ ë‹´ì— ê°–ë‹¤ì¤„ê»˜ ì €ë„ ì•Œë°”ìƒì´ë¼ ì™¸ìƒì•ˆë©ë‹ˆë‹¤ ì•„ë”° ëˆ„ê°€ ë–¼ë¨¹ëŠ”ë‹¤ê³  ê·¸ëŸ¬ë‚˜ ê°–ë‹¤ì¤€ë‹¤ê³  ì•ˆë©ë‹ˆë‹¤ ìê¾¸ì´ëŸ¼ ê²½ì°°ë¶ˆëŸ¬ìš” ì•„ê°€ì”¨ ë‹´ë°°í”¼ëŠ”êµ ê·¸ê±´ ì™œ ë¬¼ìœ¼ì„¸ìš” ê·¸ëŒ ì•„ê°€ì”¨ ë‹´ë°° í•œëŒ€ë§Œ ë¹Œë¦½ì‹œë‹¤ ë‚´ ì§€ê¸ˆ ì§€ê°‘ë„ ìƒì–´ë²„ë¦¬ê³  ê¸°ë¶„ì´ ê·¸ë˜ì„œ ê·¸ëŸ¬ë‹ˆ ì—¬ê¸°ìš”  ì•„ë”° ì£¼ëŠ”ê¹€ì— í•œê°œë” ì£¼ë©´ ë˜ê² ë„¤'}\n",
      "ëª¨ë¸ ë¡œë”© ì¤‘...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd329ce091848f89e2b0d85064043ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜ˆì¸¡ ì‹œì‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:05<00:00, 91.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: submission.csv\n",
      "==================================================\n",
      "     idx  class\n",
      "0  t_000      1\n",
      "1  t_001      2\n",
      "2  t_002      2\n",
      "3  t_003      3\n",
      "4  t_004      3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ\n",
    "MODEL_PATH = \"./final_model_ko\"       # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ\n",
    "TEST_FILE = \"test.json\"            # ì—…ë¡œë“œëœ í…ŒìŠ¤íŠ¸ íŒŒì¼\n",
    "\n",
    "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (JSON)\n",
    "try:\n",
    "    with open(TEST_FILE, 'r', encoding='utf-8') as f:\n",
    "        test_data = json.load(f)\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_data)}ê°œ\")\n",
    "    \n",
    "    # ë°ì´í„° êµ¬ì¡° í™•ì¸ (ì²« ë²ˆì§¸ ì•„ì´í…œ)\n",
    "    first_key = list(test_data.keys())[0]\n",
    "    print(f\"ë°ì´í„° ì˜ˆì‹œ: ID={first_key}, ë‚´ìš©={test_data[first_key]}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ì˜¤ë¥˜: 'test.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    # (í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°)\n",
    "    test_data = {\"t_000\": {\"text\": \"ì´ê±° ë“¤ì–´ë´ ì™€ ì´ ë…¸ë˜ ì§„ì§œ ì¢‹ë‹¤\"}, \"t_001\": {\"text\": \"ì•¼ ëˆ ë‚´ë†”\"}}\n",
    "\n",
    "\n",
    "# 2. ëª¨ë¸ ë¡œë“œ\n",
    "print(\"ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(device)\n",
    "    model.eval()\n",
    "except OSError:\n",
    "    print(\"ì˜¤ë¥˜: ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "    # (ì„ì‹œ ëª¨ë¸ ë¡œë“œ)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=5).to(device)\n",
    "\n",
    "# 3. ì¶”ë¡  (Inference)\n",
    "print(\"ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# test_dataê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ {\"t_000\": {\"text\": \"...\"}} ë¼ê³  ê°€ì •\n",
    "for idx, item in tqdm(test_data.items()):\n",
    "    # í…ìŠ¤íŠ¸ ì¶”ì¶œ (text í‚¤ê°€ ì—†ìœ¼ë©´ conversation ë“± ë‹¤ë¥¸ í‚¤ ì‹œë„)\n",
    "    text = item.get('text', item.get('conversation', ''))\n",
    "    \n",
    "    # ì „ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì§•\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "    # ì˜ˆì¸¡ê°’ (0~4)\n",
    "    pred_label = torch.argmax(logits, dim=-1).item()\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results.append({\n",
    "        'idx': idx,\n",
    "        'class': pred_label  # ìˆ«ìë¡œ ì €ì¥ (0, 1, 2, 3, 4)\n",
    "    })\n",
    "\n",
    "# 4. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "submission = pd.DataFrame(results)\n",
    "\n",
    "# ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ (idx, class)\n",
    "submission = submission[['idx', 'class']]\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "save_path = \"submission.csv\"\n",
    "submission.to_csv(save_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {save_path}\")\n",
    "print(\"=\"*50)\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b2326-e069-4c8e-befa-7f476c1416f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
