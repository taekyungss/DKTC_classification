{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RAseng77/DKTC_classification/blob/main/%EC%84%B1%ED%98%84/2_10_baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9aa4e8be-2a49-4a17-b9bd-669406fc5d8c",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "95585fa53acc40519c821a720788756f",
            "cf73c53cca5e405391e29337f892247f"
          ]
        },
        "id": "9aa4e8be-2a49-4a17-b9bd-669406fc5d8c",
        "outputId": "5519c414-ad99-44ed-ec54-5f6c41c35693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸš€ ì‚¬ìš© ì¥ì¹˜: cuda\n",
            "ìœ„í˜‘ ë°ì´í„° ë¡œë“œ: 3950ê°œ\n",
            "   â””â”€ í´ë˜ìŠ¤ ëª©ë¡: ['í˜‘ë°• ëŒ€í™”' 'ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”' 'ê°ˆì·¨ ëŒ€í™”' 'ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”']\n",
            "ì¼ë°˜ ëŒ€í™” ë°ì´í„° ë¡œë“œ: 800ê°œ\n",
            "ìµœì¢… ë°ì´í„°ì…‹ ë³‘í•© ì™„ë£Œ: 4750ê°œ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.12/site-packages/huggingface_hub/file_download.py:949: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95585fa53acc40519c821a720788756f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3800 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf73c53cca5e405391e29337f892247f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/950 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "í•™ìŠµ ì‹œì‘! (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='714' max='714' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [714/714 08:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.278700</td>\n",
              "      <td>0.911579</td>\n",
              "      <td>0.912051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.270557</td>\n",
              "      <td>0.922105</td>\n",
              "      <td>0.921966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.334500</td>\n",
              "      <td>0.312294</td>\n",
              "      <td>0.923158</td>\n",
              "      <td>0.923188</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./final_model\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "\n",
        "\n",
        "# 1. í™˜ê²½ ì„¤ì • (Seed ê³ ì •)\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(42)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
        "\n",
        "# 2. ë°ì´í„° ë¡œë“œ ë° ë³‘í•©\n",
        "# (1) DKTC ìœ„í˜‘ ë°ì´í„° ë¡œë“œ\n",
        "url = \"https://raw.githubusercontent.com/tunib-ai/DKTC/main/data/train.csv\"\n",
        "try:\n",
        "    df_threat = pd.read_csv(url)\n",
        "    df_threat = df_threat[['class', 'conversation']]\n",
        "    print(f\"ìœ„í˜‘ ë°ì´í„° ë¡œë“œ: {len(df_threat)}ê°œ\")\n",
        "    # í™•ì¸ìš©: ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ ì¶œë ¥\n",
        "    print(f\"   â””â”€ í´ë˜ìŠ¤ ëª©ë¡: {df_threat['class'].unique()}\")\n",
        "except Exception as e:\n",
        "    print(f\"ìœ„í˜‘ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "\n",
        "# (2) ì¼ë°˜ ëŒ€í™” ë°ì´í„° ë¡œë“œ\n",
        "normal_file = \"normal_conversation.csv\"\n",
        "try:\n",
        "    df_normal = pd.read_csv(normal_file)\n",
        "    # í™”ì ë¼ë²¨ ì œê±° ì „ì²˜ë¦¬\n",
        "    df_normal['conversation'] = df_normal['conversation'].str.replace(r'(^|\\n)[AB]:\\s*', '', regex=True)\n",
        "\n",
        "    if 'class' not in df_normal.columns:\n",
        "        df_normal['class'] = 'ì¼ë°˜ ëŒ€í™”'\n",
        "\n",
        "    df_normal = df_normal[['class', 'conversation']]\n",
        "    print(f\"ì¼ë°˜ ëŒ€í™” ë°ì´í„° ë¡œë“œ: {len(df_normal)}ê°œ\")\n",
        "\n",
        "    # (3) ë°ì´í„° ë³‘í•©\n",
        "    df_final = pd.concat([df_threat, df_normal], ignore_index=True)\n",
        "\n",
        "    # ì…”í”Œ\n",
        "    df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    print(f\"ìµœì¢… ë°ì´í„°ì…‹ ë³‘í•© ì™„ë£Œ: {len(df_final)}ê°œ\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ì˜¤ë¥˜: '{normal_file}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ì„ ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    df_final = df_threat.copy()\n",
        "\n",
        "# 3. ë¼ë²¨ ì¸ì½”ë”© (ìˆ˜ì •ë¨: ' ëŒ€í™”' ì¶”ê°€)\n",
        "label_map = {\n",
        "    'í˜‘ë°• ëŒ€í™”': 0,        # <-- ìˆ˜ì •ë¨\n",
        "    'ê°ˆì·¨ ëŒ€í™”': 1,        # <-- ìˆ˜ì •ë¨\n",
        "    'ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”': 2, # <-- ìˆ˜ì •ë¨\n",
        "    'ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”': 3,    # <-- ìˆ˜ì •ë¨\n",
        "    'í˜‘ë°•': 0,            # (í˜¹ì‹œ ëª°ë¼ ì›ë³¸ í‚¤ë„ ìœ ì§€)\n",
        "    'ê°ˆì·¨': 1,\n",
        "    'ì§ì¥ ë‚´ ê´´ë¡­í˜': 2,\n",
        "    'ê¸°íƒ€ ê´´ë¡­í˜': 3,\n",
        "    'ì¼ë°˜ ëŒ€í™”': 4\n",
        "}\n",
        "\n",
        "df_final['label'] = df_final['class'].map(label_map)\n",
        "\n",
        "# NaN í™•ì¸ (ë””ë²„ê¹…ìš©)\n",
        "if df_final['label'].isnull().sum() > 0:\n",
        "    print(f\"ê²½ê³ : ë¼ë²¨ë§ ì‹¤íŒ¨í•œ ë°ì´í„°ê°€ {df_final['label'].isnull().sum()}ê°œ ìˆìŠµë‹ˆë‹¤.\")\n",
        "    print(df_final[df_final['label'].isnull()]['class'].unique())\n",
        "    # NaN ë°ì´í„° ì œê±°\n",
        "    df_final = df_final.dropna(subset=['label'])\n",
        "    df_final['label'] = df_final['label'].astype(int)\n",
        "\n",
        "# 4. HuggingFace Dataset ë³€í™˜\n",
        "# Train / Validation ë¶„ë¦¬ (8:2)\n",
        "train_df, val_df = train_test_split(df_final, test_size=0.2, random_state=42, stratify=df_final['label'])\n",
        "\n",
        "# Dataset ê°ì²´ ìƒì„±\n",
        "train_dataset = Dataset.from_pandas(train_df[['conversation', 'label']])\n",
        "val_dataset = Dataset.from_pandas(val_df[['conversation', 'label']])\n",
        "\n",
        "\n",
        "# 5. í† í¬ë‚˜ì´ì € ë° ëª¨ë¸ ì¤€ë¹„\n",
        "MODEL_NAME = \"klue/bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"conversation\"], truncation=True, max_length=256)\n",
        "\n",
        "tokenized_train = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_val = val_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# ëª¨ë¸ ì´ˆê¸°í™”\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=5,\n",
        "    id2label={0: 'í˜‘ë°•', 1: 'ê°ˆì·¨', 2: 'ì§ì¥ ê´´ë¡­í˜', 3: 'ê¸°íƒ€ ê´´ë¡­í˜', 4: 'ì¼ë°˜ ëŒ€í™”'},\n",
        "    label2id={'í˜‘ë°•': 0, 'ê°ˆì·¨': 1, 'ì§ì¥ ê´´ë¡­í˜': 2, 'ê¸°íƒ€ ê´´ë¡­í˜': 3, 'ì¼ë°˜ ëŒ€í™”': 4}\n",
        ").to(device)\n",
        "\n",
        "# 6. í•™ìŠµ (Training)\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    acc = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average='weighted')\n",
        "    return {\"accuracy\": acc, \"f1\": f1}\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "print(\"\\ní•™ìŠµ ì‹œì‘! (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...)\")\n",
        "trainer.train()\n",
        "\n",
        "# ëª¨ë¸ ì €ì¥\n",
        "model.save_pretrained(\"./final_model\")\n",
        "tokenizer.save_pretrained(\"./final_model\")\n",
        "print(\"\\nëª¨ë¸ ì €ì¥ ì™„ë£Œ: ./final_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39a8332e-9e4a-401b-a30e-b00611144a98",
      "metadata": {
        "id": "39a8332e-9e4a-401b-a30e-b00611144a98",
        "outputId": "96c5f407-f1fc-4339-d8f7-4f30054d146d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ: ì´ 500ê°œ\n",
            "class\n",
            "í˜‘ë°• ëŒ€í™”          100\n",
            "ê°ˆì·¨ ëŒ€í™”          100\n",
            "ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”    100\n",
            "ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”      100\n",
            "ì¼ë°˜ ëŒ€í™”          100\n",
            "Name: count, dtype: int64\n",
            "\n",
            "ëª¨ë¸ ë¡œë”© ì¤‘...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2598/3722797554.py:38: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  test_df = df.groupby('label').apply(lambda x: x.sample(n=100, random_state=42)).reset_index(drop=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì˜ˆì¸¡ ì‹œì‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\n",
            "\n",
            "==================================================\n",
            "[ìµœì¢… ëª¨ë¸ í‰ê°€ ë¦¬í¬íŠ¸ (Test Set: 100 samples/class)]\n",
            "==================================================\n",
            "ì •í™•ë„ (Accuracy): 0.9660\n",
            "F1 ì ìˆ˜ (Weighted): 0.9659\n",
            "--------------------------------------------------\n",
            "\n",
            "[í´ë˜ìŠ¤ë³„ ìƒì„¸ ì§€í‘œ]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          í˜‘ë°•     0.9604    0.9700    0.9652       100\n",
            "          ê°ˆì·¨     0.9588    0.9300    0.9442       100\n",
            "      ì§ì¥ ê´´ë¡­í˜     0.9519    0.9900    0.9706       100\n",
            "      ê¸°íƒ€ ê´´ë¡­í˜     0.9592    0.9400    0.9495       100\n",
            "       ì¼ë°˜ ëŒ€í™”     1.0000    1.0000    1.0000       100\n",
            "\n",
            "    accuracy                         0.9660       500\n",
            "   macro avg     0.9661    0.9660    0.9659       500\n",
            "weighted avg     0.9661    0.9660    0.9659       500\n",
            "\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# 1. ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n",
        "MODEL_PATH = \"./final_model\"       # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ\n",
        "DATA_PATH = \"final_train_dataset.csv\" # ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ë°ì´í„° ë¡œë“œ\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df['conversation'] = df['conversation'].astype(str)\n",
        "\n",
        "# ë¼ë²¨ ì¬ë§¤í•‘ (ì•ˆì „ì¥ì¹˜)\n",
        "label_map = {\n",
        "    'í˜‘ë°• ëŒ€í™”': 0, 'ê°ˆì·¨ ëŒ€í™”': 1, 'ì§ì¥ ë‚´ ê´´ë¡­í˜ ëŒ€í™”': 2, 'ê¸°íƒ€ ê´´ë¡­í˜ ëŒ€í™”': 3,\n",
        "    'í˜‘ë°•': 0, 'ê°ˆì·¨': 1, 'ì§ì¥ ë‚´ ê´´ë¡­í˜': 2, 'ê¸°íƒ€ ê´´ë¡­í˜': 3,\n",
        "    'ì§ì¥ ê´´ë¡­í˜': 2, 'ê¸°íƒ€ ê´´ë¡­í˜': 3,\n",
        "    'ì¼ë°˜ ëŒ€í™”': 4\n",
        "}\n",
        "df['label'] = df['class'].map(label_map)\n",
        "\n",
        "# ê²°ì¸¡ì¹˜ ì œê±°\n",
        "df = df.dropna(subset=['label'])\n",
        "df['label'] = df['label'].astype(int)\n",
        "\n",
        "\n",
        "# [í•µì‹¬] í´ë˜ìŠ¤ë³„ 100ê°œì”© ê· í˜• ìƒ˜í”Œë§\n",
        "# ê° ë¼ë²¨ë³„ë¡œ ëœë¤í•˜ê²Œ 100ê°œì”© ë½‘ìŠµë‹ˆë‹¤.\n",
        "try:\n",
        "    test_df = df.groupby('label').apply(lambda x: x.sample(n=100, random_state=42)).reset_index(drop=True)\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ êµ¬ì„± ì™„ë£Œ: ì´ {len(test_df)}ê°œ\")\n",
        "    print(test_df['class'].value_counts()) # ê° 100ê°œì¸ì§€ í™•ì¸\n",
        "except ValueError as e:\n",
        "    print(f\"ì˜¤ë¥˜: ë°ì´í„°ê°€ ë¶€ì¡±í•˜ì—¬ í´ë˜ìŠ¤ë³„ 100ê°œë¥¼ ë½‘ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ({e})\")\n",
        "    # ì˜ˆì™¸ ì‹œ ì „ì²´ ë°ì´í„° ì‚¬ìš©\n",
        "    test_df = df\n",
        "\n",
        "# 2. ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡\n",
        "print(\"\\nëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(device)\n",
        "    model.eval()\n",
        "except OSError:\n",
        "    print(\"ì˜¤ë¥˜: ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    # (ì½”ë“œê°€ ë©ˆì¶”ì§€ ì•Šë„ë¡ ì„ì‹œ ì¢…ë£Œ ì²˜ë¦¬ í•„ìš” ì‹œ exit())\n",
        "\n",
        "# ì˜ˆì¸¡ í•¨ìˆ˜\n",
        "def predict_batch(texts, batch_size=32):\n",
        "    all_preds = []\n",
        "    # ë°ì´í„°ê°€ ë§ì„ ê²½ìš° ë°°ì¹˜ë¥¼ ë‚˜ëˆ ì„œ ì²˜ë¦¬\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        inputs = tokenizer(batch, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "        all_preds.extend(preds)\n",
        "    return np.array(all_preds)\n",
        "\n",
        "print(\"ì˜ˆì¸¡ ì‹œì‘... (ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”)\")\n",
        "y_true = test_df['label'].tolist()\n",
        "y_pred = predict_batch(test_df['conversation'].tolist())\n",
        "\n",
        "\n",
        "# 3. í‰ê°€ ì§€í‘œ ì¶œë ¥ (Text Only)\n",
        "target_names = ['í˜‘ë°•', 'ê°ˆì·¨', 'ì§ì¥ ê´´ë¡­í˜', 'ê¸°íƒ€ ê´´ë¡­í˜', 'ì¼ë°˜ ëŒ€í™”']\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"[ìµœì¢… ëª¨ë¸ í‰ê°€ ë¦¬í¬íŠ¸ (Test Set: 100 samples/class)]\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Accuracy & F1-Score\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred, average='weighted') # ê° í´ë˜ìŠ¤ ë¹„ì¤‘ì´ ê°™ìœ¼ë¯€ë¡œ macroì™€ ìœ ì‚¬í•¨\n",
        "\n",
        "print(f\"ì •í™•ë„ (Accuracy): {acc:.4f}\")\n",
        "print(f\"F1 ì ìˆ˜ (Weighted): {f1:.4f}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 2. Classification Report (ìƒì„¸ ì§€í‘œ)\n",
        "print(\"\\n[í´ë˜ìŠ¤ë³„ ìƒì„¸ ì§€í‘œ]\")\n",
        "# digits=4 ì˜µì…˜ìœ¼ë¡œ ì†Œìˆ˜ì  4ìë¦¬ê¹Œì§€ ì •ë°€í•˜ê²Œ ì¶œë ¥\n",
        "print(classification_report(y_true, y_pred, target_names=target_names, digits=4))\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0313cdd2-1921-4cff-b0d9-fc22dc8e7f0c",
      "metadata": {
        "id": "0313cdd2-1921-4cff-b0d9-fc22dc8e7f0c",
        "outputId": "5c473aba-1877-4bc4-e389-9c8c21695154"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ì‚¬ìš© ì¥ì¹˜: cuda\n",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 500ê°œ\n",
            "ë°ì´í„° ì˜ˆì‹œ: ID=t_000, ë‚´ìš©={'text': 'ì•„ê°€ì”¨ ë‹´ë°°í•œê°‘ì£¼ì†Œ ë„¤ 4500ì›ì…ë‹ˆë‹¤ ì–´ ë„¤ ì§€ê°‘ì–´ë””ê°”ì§€ ì—ì´ ë²„ìŠ¤ì—ì„œ ìƒì–´ë²„ë ¸ë‚˜ë³´ë„¤ ê·¸ëŸ¼ ì·¨ì†Œí• ê¹Œìš” ì•„ê°€ì”¨ ë‚´ ì—¬ê¸°ë‹¨ê³¨ì´ë‹ˆ ë‹´ì— ê°–ë‹¤ì¤„ê»˜ ì €ë„ ì•Œë°”ìƒì´ë¼ ì™¸ìƒì•ˆë©ë‹ˆë‹¤ ì•„ë”° ëˆ„ê°€ ë–¼ë¨¹ëŠ”ë‹¤ê³  ê·¸ëŸ¬ë‚˜ ê°–ë‹¤ì¤€ë‹¤ê³  ì•ˆë©ë‹ˆë‹¤ ìê¾¸ì´ëŸ¼ ê²½ì°°ë¶ˆëŸ¬ìš” ì•„ê°€ì”¨ ë‹´ë°°í”¼ëŠ”êµ ê·¸ê±´ ì™œ ë¬¼ìœ¼ì„¸ìš” ê·¸ëŒ ì•„ê°€ì”¨ ë‹´ë°° í•œëŒ€ë§Œ ë¹Œë¦½ì‹œë‹¤ ë‚´ ì§€ê¸ˆ ì§€ê°‘ë„ ìƒì–´ë²„ë¦¬ê³  ê¸°ë¶„ì´ ê·¸ë˜ì„œ ê·¸ëŸ¬ë‹ˆ ì—¬ê¸°ìš”  ì•„ë”° ì£¼ëŠ”ê¹€ì— í•œê°œë” ì£¼ë©´ ë˜ê² ë„¤'}\n",
            "ëª¨ë¸ ë¡œë”© ì¤‘...\n",
            "ì˜ˆì¸¡ ì‹œì‘...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:05<00:00, 83.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: submission.csv\n",
            "==================================================\n",
            "     idx  class\n",
            "0  t_000      1\n",
            "1  t_001      2\n",
            "2  t_002      2\n",
            "3  t_003      3\n",
            "4  t_004      3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "# 1. ì„¤ì • ë° ë°ì´í„° ë¡œë“œ\n",
        "MODEL_PATH = \"./final_model\"       # í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ\n",
        "TEST_FILE = \"test.json\"            # ì—…ë¡œë“œëœ í…ŒìŠ¤íŠ¸ íŒŒì¼\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"ì‚¬ìš© ì¥ì¹˜: {device}\")\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ (JSON)\n",
        "try:\n",
        "    with open(TEST_FILE, 'r', encoding='utf-8') as f:\n",
        "        test_data = json.load(f)\n",
        "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(test_data)}ê°œ\")\n",
        "\n",
        "    # ë°ì´í„° êµ¬ì¡° í™•ì¸ (ì²« ë²ˆì§¸ ì•„ì´í…œ)\n",
        "    first_key = list(test_data.keys())[0]\n",
        "    print(f\"ë°ì´í„° ì˜ˆì‹œ: ID={first_key}, ë‚´ìš©={test_data[first_key]}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"ì˜¤ë¥˜: 'test.json' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    # (í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ë°ì´í„°)\n",
        "    test_data = {\"t_000\": {\"text\": \"ì´ê±° ë“¤ì–´ë´ ì™€ ì´ ë…¸ë˜ ì§„ì§œ ì¢‹ë‹¤\"}, \"t_001\": {\"text\": \"ì•¼ ëˆ ë‚´ë†”\"}}\n",
        "\n",
        "\n",
        "# 2. ëª¨ë¸ ë¡œë“œ\n",
        "print(\"ëª¨ë¸ ë¡œë”© ì¤‘...\")\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH).to(device)\n",
        "    model.eval()\n",
        "except OSError:\n",
        "    print(\"ì˜¤ë¥˜: ì €ì¥ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í•™ìŠµ ì½”ë“œë¥¼ ë¨¼ì € ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
        "    # (ì„ì‹œ ëª¨ë¸ ë¡œë“œ)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"klue/bert-base\")\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\"klue/bert-base\", num_labels=5).to(device)\n",
        "\n",
        "# 3. ì¶”ë¡  (Inference)\n",
        "print(\"ì˜ˆì¸¡ ì‹œì‘...\")\n",
        "\n",
        "results = []\n",
        "\n",
        "# test_dataê°€ ë”•ì…”ë„ˆë¦¬ í˜•íƒœ {\"t_000\": {\"text\": \"...\"}} ë¼ê³  ê°€ì •\n",
        "for idx, item in tqdm(test_data.items()):\n",
        "    # í…ìŠ¤íŠ¸ ì¶”ì¶œ (text í‚¤ê°€ ì—†ìœ¼ë©´ conversation ë“± ë‹¤ë¥¸ í‚¤ ì‹œë„)\n",
        "    text = item.get('text', item.get('conversation', ''))\n",
        "\n",
        "    # ì „ì²˜ë¦¬ ë° í† í¬ë‚˜ì´ì§•\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=256).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # ì˜ˆì¸¡ê°’ (0~4)\n",
        "    pred_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # ê²°ê³¼ ì €ì¥\n",
        "    results.append({\n",
        "        'idx': idx,\n",
        "        'class': pred_label  # ìˆ«ìë¡œ ì €ì¥ (0, 1, 2, 3, 4)\n",
        "    })\n",
        "\n",
        "# 4. ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "submission = pd.DataFrame(results)\n",
        "\n",
        "# ì»¬ëŸ¼ ìˆœì„œ ì •ë ¬ (idx, class)\n",
        "submission = submission[['idx', 'class']]\n",
        "\n",
        "# íŒŒì¼ ì €ì¥\n",
        "save_path = \"submission.csv\"\n",
        "submission.to_csv(save_path, index=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {save_path}\")\n",
        "print(\"=\"*50)\n",
        "print(submission.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0a4572d-c846-4836-a88e-874d25fa93fc",
      "metadata": {
        "id": "a0a4572d-c846-4836-a88e-874d25fa93fc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}